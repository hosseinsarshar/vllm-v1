nohup: ignoring input
WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.
INFO 04-01 18:19:04 [__init__.py:239] Automatically detected platform tpu.
WARNING 04-01 18:19:05 [api_server.py:755] Torch Profiler is enabled in the API server. This should ONLY be used for local development!
INFO 04-01 18:19:05 [api_server.py:1031] vLLM API server version 0.7.4.dev811+gc1d633ce7
INFO 04-01 18:19:05 [api_server.py:1032] args: Namespace(subparser='serve', model_tag='meta-llama/Meta-Llama-3.1-8B', config='', host=None, port=8000, uvicorn_log_level='info', disable_uvicorn_access_log=False, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Meta-Llama-3.1-8B', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir='/dev/shm', load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=512, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=1, data_parallel_size=1, enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, prefix_caching_hash_algo='builtin', disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=None, swap_space=16.0, cpu_offload_gb=0, gpu_memory_utilization=0.95, num_gpu_blocks_override=None, max_num_batched_tokens=512, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=128, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, use_tqdm_on_load=True, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_config=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', worker_extension_cls='', generation_config='auto', override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, enable_reasoning=False, reasoning_parser=None, disable_cascade_attn=False, disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, enable_server_load_tracking=False, dispatch_function=<function ServeSubcommand.cmd at 0x784d09071b40>)
INFO 04-01 18:19:13 [config.py:598] This model supports multiple tasks: {'embed', 'classify', 'score', 'reward', 'generate'}. Defaulting to 'generate'.
WARNING 04-01 18:19:13 [arg_utils.py:1702] Detected VLLM_USE_V1=1 with tpu. Usage should be considered experimental. Please report any issues on Github.
INFO 04-01 18:19:13 [config.py:1758] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 04-01 18:19:13 [tpu.py:81] [TPU] Forcing DYNAMO_ONCE compilation level
INFO 04-01 18:19:19 [__init__.py:239] Automatically detected platform tpu.
INFO 04-01 18:19:20 [core.py:61] Initializing a V1 LLM engine (v0.7.4.dev811+gc1d633ce7) with config: model='meta-llama/Meta-Llama-3.1-8B', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir='/dev/shm', load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=None, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Meta-Llama-3.1-8B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":2,"backend":"openxla","custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
hosseins: init_worker() self.vllm_config.parallel_config.worker_cls='vllm.v1.worker.tpu_worker.TPUWorker'
INFO 04-01 18:19:35 [utils.py:377] Initializing SPMD engine with mesh=[{'device_ids': [0, 1, 2, 3], 'mesh_shape': (4,), 'axis_names': ('axis',)}]
hosseins: envs.VLLM_TORCH_PROFILER_DIR='gs://hosseins-asia-northeast1-bucket/vllm/profile-dev'
INFO 04-01 18:19:35 [tpu_worker.py:95] Profiling enabled. Traces will be saved to: gs://hosseins-asia-northeast1-bucket/vllm/profile-dev
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
hosseins: initialize_model_parallel() world_size=1
hosseins: initialize_model_parallel() all_ranks=tensor([[[[0]]]])
INFO 04-01 18:19:35 [parallel_state.py:956] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
WARNING 04-01 18:19:35 [tpu.py:121] Pin memory is not supported on TPU.
INFO 04-01 18:19:35 [tpu_model_runner.py:1061] Using exponential paddings:
INFO 04-01 18:19:35 [tpu_model_runner.py:1063]     16
INFO 04-01 18:19:35 [tpu_model_runner.py:1063]     32
INFO 04-01 18:19:35 [tpu_model_runner.py:1063]     64
INFO 04-01 18:19:35 [tpu_model_runner.py:1063]     128
INFO 04-01 18:19:35 [tpu_model_runner.py:1063]     256
INFO 04-01 18:19:35 [tpu_model_runner.py:1063]     512
hosseins: get_model_loader() load_config.load_format=<LoadFormat.AUTO: 'auto'>
INFO 04-01 18:19:35 [tpu.py:44] Cannot use None backend on TPU.
INFO 04-01 18:19:35 [tpu.py:47] Using Pallas V1 backend.
INFO 04-01 18:19:36 [weight_utils.py:266] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
2025-04-01 18:19:36.965002: W torch_xla/csrc/xla_graph_executor.cpp:105] Using persistent compilation cache with XLA_HLO_DEBUG=1 or XLA_IR_DEBUG=1 is not recommended. Changes to the HLO metadata will not be reflected in loaded executables.
hosseins: DefaultModelLoader -> load_weights() name='layers.20.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.20.mlp.down_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.20.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.20.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.mlp.down_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.self_attn.k_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.self_attn.o_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.self_attn.q_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.21.self_attn.v_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.mlp.down_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.self_attn.k_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.self_attn.o_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.self_attn.q_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.22.self_attn.v_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.mlp.down_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.self_attn.k_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.self_attn.o_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.self_attn.q_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.23.self_attn.v_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.mlp.down_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:37 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:37 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:37 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.self_attn.k_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.self_attn.o_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.self_attn.q_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.24.self_attn.v_proj.weight'
INFO 04-01 18:19:37 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:37 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:37 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.mlp.down_proj.weight'
INFO 04-01 18:19:37 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:37 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:37 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.self_attn.k_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.self_attn.o_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.self_attn.q_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.25.self_attn.v_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.mlp.down_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.self_attn.k_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.self_attn.o_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.self_attn.q_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.26.self_attn.v_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.mlp.down_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.self_attn.k_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.self_attn.o_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.self_attn.q_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.27.self_attn.v_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.mlp.down_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.self_attn.k_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.self_attn.o_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.self_attn.q_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.28.self_attn.v_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.mlp.down_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.self_attn.k_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.self_attn.o_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.self_attn.q_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.29.self_attn.v_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.mlp.down_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.self_attn.k_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.self_attn.o_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.self_attn.q_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.30.self_attn.v_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.31.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.31.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:38 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:38 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:38 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.31.self_attn.k_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.31.self_attn.o_proj.weight'
INFO 04-01 18:19:38 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.31.self_attn.q_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.31.self_attn.v_proj.weight'
INFO 04-01 18:19:38 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:38 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:38 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:38 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:05,  2.00s/it]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: ============================= Layers Loaded =============================
hosseins: [embed_tokens.weight] - [torch.Size([128256, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='']
hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [norm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: VocabParallelEmbedding -> weight_loader() [start_idx=0]
hosseins: VocabParallelEmbedding -> weight_loader() [shard_size=128256]
hosseins: DefaultModelLoader -> load_weights() name='layers.31.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.31.mlp.down_proj.weight'
INFO 04-01 18:19:39 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:39 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:39 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:39 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:39 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:39 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.34s/it]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.31.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='norm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.mlp.down_proj.weight'
INFO 04-01 18:19:39 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:39 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:39 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:39 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:39 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:39 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:39 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:39 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:39 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:39 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:39 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:39 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:39 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:39 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:39 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:39 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:39 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:39 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.self_attn.k_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.self_attn.o_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.self_attn.q_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.10.self_attn.v_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.mlp.down_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.self_attn.k_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.self_attn.o_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.self_attn.q_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.11.self_attn.v_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.mlp.down_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.self_attn.k_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.self_attn.o_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.self_attn.q_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.12.self_attn.v_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.mlp.down_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.self_attn.k_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.self_attn.o_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.self_attn.q_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.13.self_attn.v_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.mlp.down_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.self_attn.k_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.self_attn.o_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.self_attn.q_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.14.self_attn.v_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.mlp.down_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.self_attn.k_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.self_attn.o_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.self_attn.q_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.15.self_attn.v_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.mlp.down_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.self_attn.k_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.self_attn.o_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.self_attn.q_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.16.self_attn.v_proj.weight'
INFO 04-01 18:19:40 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:40 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:40 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.mlp.down_proj.weight'
INFO 04-01 18:19:40 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:40 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:40 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:40 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:40 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:40 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:41 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:41 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.self_attn.k_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.self_attn.o_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.self_attn.q_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.17.self_attn.v_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.mlp.down_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:41 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:41 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:41 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:41 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.self_attn.k_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.self_attn.o_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.self_attn.q_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.18.self_attn.v_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.mlp.down_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:41 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:41 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:41 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:41 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.self_attn.k_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.self_attn.o_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.self_attn.q_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.19.self_attn.v_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.20.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:41 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:41 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.20.self_attn.k_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.20.self_attn.o_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.20.self_attn.q_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.20.self_attn.v_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.mlp.down_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:41 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:41 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:41 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:41 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:41 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.self_attn.k_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.self_attn.o_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.self_attn.q_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.9.self_attn.v_proj.weight'
INFO 04-01 18:19:41 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:41 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:41 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:04<00:01,  1.52s/it]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='embed_tokens.weight'
hosseins: VocabParallelEmbedding -> weight_loader() [start_idx=0]
hosseins: VocabParallelEmbedding -> weight_loader() [shard_size=128256]
hosseins: DefaultModelLoader -> load_weights() name='layers.0.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.0.mlp.down_proj.weight'
INFO 04-01 18:19:41 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:41 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:41 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.0.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:42 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:42 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.0.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:42 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:42 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.0.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.0.self_attn.k_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.0.self_attn.o_proj.weight'
INFO 04-01 18:19:42 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.0.self_attn.q_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.0.self_attn.v_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.mlp.down_proj.weight'
INFO 04-01 18:19:42 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:42 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:42 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:42 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:42 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.self_attn.k_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.self_attn.o_proj.weight'
INFO 04-01 18:19:42 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.self_attn.q_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.1.self_attn.v_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.mlp.down_proj.weight'
INFO 04-01 18:19:42 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:42 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:42 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:42 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:42 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.self_attn.k_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.self_attn.o_proj.weight'
INFO 04-01 18:19:42 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.self_attn.q_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.2.self_attn.v_proj.weight'
INFO 04-01 18:19:42 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:42 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:42 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.mlp.down_proj.weight'
INFO 04-01 18:19:42 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:42 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:42 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:42 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:42 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:42 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:42 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:42 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.self_attn.k_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.self_attn.o_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.self_attn.q_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.3.self_attn.v_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.mlp.down_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.self_attn.k_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.self_attn.o_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.self_attn.q_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.4.self_attn.v_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.mlp.down_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.self_attn.k_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.self_attn.o_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.self_attn.q_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.5.self_attn.v_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.mlp.down_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.self_attn.k_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.self_attn.o_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.self_attn.q_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.6.self_attn.v_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.mlp.down_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.self_attn.k_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.self_attn.o_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.self_attn.q_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.7.self_attn.v_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.input_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.mlp.down_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 14336])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 14336])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.mlp.gate_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{replicated}'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.mlp.up_proj.weight'
hosseins: MergedColumnParallelLinear -> weight_loader() 1 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 2 get_shard_spec(param_data.data)=''
INFO 04-01 18:19:43 [linear.py:733] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:734] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:735] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.shape=torch.Size([28672, 4096])]
INFO 04-01 18:19:43 [linear.py:736] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:737] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([14336, 4096])]
INFO 04-01 18:19:43 [linear.py:738] hosseins: MergedColumnParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([28672, 4096])]
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: MergedColumnParallelLinear -> weight_loader() 3 get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.post_attention_layernorm.weight'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.self_attn.k_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.self_attn.o_proj.weight'
INFO 04-01 18:19:43 [linear.py:1302] hosseins: RowParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1303] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1304] hosseins: RowParallelLinear -> weight_loader() 2 [param.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1305] hosseins: RowParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1306] hosseins: RowParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1307] hosseins: RowParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([4096, 4096])]
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[1,4]0,1,2,3}'
hosseins: RowParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[1,4]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.self_attn.q_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([4096, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: DefaultModelLoader -> load_weights() name='layers.8.self_attn.v_proj.weight'
INFO 04-01 18:19:43 [linear.py:1168] hosseins: QKVParallelLinear -> weight_loader() 2 [param.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1169] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.device=device(type='xla', index=0)]
INFO 04-01 18:19:43 [linear.py:1170] hosseins: QKVParallelLinear -> weight_loader() 2 [param.shape=torch.Size([6144, 4096])]
INFO 04-01 18:19:43 [linear.py:1171] hosseins: QKVParallelLinear -> weight_loader() 2 [loaded_weight.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1172] hosseins: QKVParallelLinear -> weight_loader() 2 [param_data.shape=torch.Size([1024, 4096])]
INFO 04-01 18:19:43 [linear.py:1173] hosseins: QKVParallelLinear -> weight_loader() 2 [param.data.shape=torch.Size([6144, 4096])]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:06<00:00,  1.79s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:06<00:00,  1.70s/it]

hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param.data)='{devices=[4,1]0,1,2,3}'
hosseins: QKVParallelLinear -> weight_loader() get_shard_spec(param_data.data)='{devices=[4,1]0,1,2,3}'
hosseins: ============================= Layers Loaded =============================
hosseins: [embed_tokens.weight] - [torch.Size([128256, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='']
hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([6144, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 4096])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([28672, 4096])] - [get_shard_spec(param)='{devices=[4,1]0,1,2,3}']
hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 14336])] - [get_shard_spec(param)='{devices=[1,4]0,1,2,3}']
hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
hosseins: [norm.weight] - [torch.Size([4096])] - [get_shard_spec(param)='{replicated}']
INFO 04-01 18:19:43 [loader.py:448] Loading weights took 6.99 seconds
hosseins: _initialize_kv_caches() self.model_executor=<vllm.v1.executor.abstract.UniProcExecutor object at 0x75fca262c4c0>
hosseins: _initialize_kv_caches() kv_cache_specs=[{'model.layers.0.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.1.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.2.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.3.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.4.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.5.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.6.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.7.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.8.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.9.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.10.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.11.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.12.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.13.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.14.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.15.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.16.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.17.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.18.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.19.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.20.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.21.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.22.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.23.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.24.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.25.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.26.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.27.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.28.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.29.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.30.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.31.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False)}]
hosseins: [kv_cache_spec={'model.layers.0.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.1.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.2.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.3.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.4.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.5.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.6.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.7.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.8.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.9.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.10.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.11.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.12.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.13.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.14.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.15.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.16.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.17.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.18.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.19.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.20.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.21.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.22.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.23.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.24.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.25.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.26.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.27.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.28.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.29.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.30.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.31.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False)}]
hosseins: _initialize_kv_caches() available_gpu_memory=[27544016844]
hosseins: page_sizes={65536}
hosseins: page_size=65536
hosseins: available_memory=27544016844
hosseins: num_blocks=13134
hosseins: num_blocks=13134
hosseins: vllm_config.cache_config.num_gpu_blocks_override=None
hosseins: vllm_config.cache_config.block_size=16
hosseins: num_tokens=210144
INFO 04-01 18:20:15 [kv_cache_utils.py:588] GPU KV cache size: 210,144 tokens
INFO 04-01 18:20:15 [kv_cache_utils.py:591] Maximum concurrency for 512 tokens per request: 410.44x
hosseins: _initialize_kv_caches() kv_cache_configs=[KVCacheConfig(num_blocks=13134, tensors={'model.layers.0.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.1.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.2.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.3.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.4.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.5.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.6.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.7.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.8.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.9.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.10.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.11.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.12.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.13.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.14.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.15.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.16.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.17.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.18.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.19.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.20.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.21.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.22.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.23.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.24.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.25.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.26.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.27.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.28.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.29.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.30.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.31.self_attn.attn': KVCacheTensor(size=860749824)}, kv_cache_groups=[KVCacheGroupSpec(layer_names=['model.layers.0.self_attn.attn', 'model.layers.1.self_attn.attn', 'model.layers.2.self_attn.attn', 'model.layers.3.self_attn.attn', 'model.layers.4.self_attn.attn', 'model.layers.5.self_attn.attn', 'model.layers.6.self_attn.attn', 'model.layers.7.self_attn.attn', 'model.layers.8.self_attn.attn', 'model.layers.9.self_attn.attn', 'model.layers.10.self_attn.attn', 'model.layers.11.self_attn.attn', 'model.layers.12.self_attn.attn', 'model.layers.13.self_attn.attn', 'model.layers.14.self_attn.attn', 'model.layers.15.self_attn.attn', 'model.layers.16.self_attn.attn', 'model.layers.17.self_attn.attn', 'model.layers.18.self_attn.attn', 'model.layers.19.self_attn.attn', 'model.layers.20.self_attn.attn', 'model.layers.21.self_attn.attn', 'model.layers.22.self_attn.attn', 'model.layers.23.self_attn.attn', 'model.layers.24.self_attn.attn', 'model.layers.25.self_attn.attn', 'model.layers.26.self_attn.attn', 'model.layers.27.self_attn.attn', 'model.layers.28.self_attn.attn', 'model.layers.29.self_attn.attn', 'model.layers.30.self_attn.attn', 'model.layers.31.self_attn.attn'], kv_cache_spec=FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False))])]
hosseins: _initialize_kv_caches() num_gpu_blocks=13134
hosseins: initialize_from_config() kv_cache_config=KVCacheConfig(num_blocks=13134, tensors={'model.layers.0.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.1.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.2.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.3.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.4.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.5.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.6.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.7.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.8.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.9.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.10.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.11.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.12.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.13.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.14.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.15.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.16.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.17.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.18.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.19.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.20.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.21.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.22.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.23.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.24.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.25.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.26.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.27.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.28.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.29.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.30.self_attn.attn': KVCacheTensor(size=860749824), 'model.layers.31.self_attn.attn': KVCacheTensor(size=860749824)}, kv_cache_groups=[KVCacheGroupSpec(layer_names=['model.layers.0.self_attn.attn', 'model.layers.1.self_attn.attn', 'model.layers.2.self_attn.attn', 'model.layers.3.self_attn.attn', 'model.layers.4.self_attn.attn', 'model.layers.5.self_attn.attn', 'model.layers.6.self_attn.attn', 'model.layers.7.self_attn.attn', 'model.layers.8.self_attn.attn', 'model.layers.9.self_attn.attn', 'model.layers.10.self_attn.attn', 'model.layers.11.self_attn.attn', 'model.layers.12.self_attn.attn', 'model.layers.13.self_attn.attn', 'model.layers.14.self_attn.attn', 'model.layers.15.self_attn.attn', 'model.layers.16.self_attn.attn', 'model.layers.17.self_attn.attn', 'model.layers.18.self_attn.attn', 'model.layers.19.self_attn.attn', 'model.layers.20.self_attn.attn', 'model.layers.21.self_attn.attn', 'model.layers.22.self_attn.attn', 'model.layers.23.self_attn.attn', 'model.layers.24.self_attn.attn', 'model.layers.25.self_attn.attn', 'model.layers.26.self_attn.attn', 'model.layers.27.self_attn.attn', 'model.layers.28.self_attn.attn', 'model.layers.29.self_attn.attn', 'model.layers.30.self_attn.attn', 'model.layers.31.self_attn.attn'], kv_cache_spec=FullAttentionSpec(block_size=16, num_kv_heads=8, head_size=128, dtype=torch.bfloat16, use_mla=False))])
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
hosseins: [kv_cache_shape=(13134, 16, 16, 128)]
INFO 04-01 18:20:15 [tpu_model_runner.py:840] Compiling the model with different input shapes.
INFO 04-01 18:20:15 [tpu_model_runner.py:844]   -- num_tokens: 16
/home/hosseins/miniconda3/envs/vllm-march/lib/python3.10/site-packages/jax/_src/cloud_tpu_init.py:82: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c "echo always > /sys/kernel/mm/transparent_hugepage/enabled")
  warnings.warn(
INFO 04-01 18:20:54 [tpu_model_runner.py:844]   -- num_tokens: 32
INFO 04-01 18:21:07 [tpu_model_runner.py:844]   -- num_tokens: 64
INFO 04-01 18:21:21 [tpu_model_runner.py:844]   -- num_tokens: 128
INFO 04-01 18:21:36 [tpu_model_runner.py:844]   -- num_tokens: 256
INFO 04-01 18:21:56 [tpu_model_runner.py:844]   -- num_tokens: 512
INFO 04-01 18:22:24 [tpu_model_runner.py:850] Compilation finished in in 129.32 [secs].
INFO 04-01 18:22:24 [tpu_model_runner.py:853] Compiling sampling with different input shapes.
INFO 04-01 18:22:24 [tpu_model_runner.py:874]   -- num_tokens: 16, num_seqs: 8
INFO 04-01 18:22:25 [tpu_model_runner.py:874]   -- num_tokens: 16, num_seqs: 16
INFO 04-01 18:22:26 [tpu_model_runner.py:874]   -- num_tokens: 16, num_seqs: 32
INFO 04-01 18:22:27 [tpu_model_runner.py:874]   -- num_tokens: 16, num_seqs: 64
INFO 04-01 18:22:29 [tpu_model_runner.py:874]   -- num_tokens: 16, num_seqs: 128
INFO 04-01 18:22:30 [tpu_model_runner.py:874]   -- num_tokens: 32, num_seqs: 8
INFO 04-01 18:22:31 [tpu_model_runner.py:874]   -- num_tokens: 32, num_seqs: 16
INFO 04-01 18:22:32 [tpu_model_runner.py:874]   -- num_tokens: 32, num_seqs: 32
INFO 04-01 18:22:33 [tpu_model_runner.py:874]   -- num_tokens: 32, num_seqs: 64
INFO 04-01 18:22:34 [tpu_model_runner.py:874]   -- num_tokens: 32, num_seqs: 128
INFO 04-01 18:22:36 [tpu_model_runner.py:874]   -- num_tokens: 64, num_seqs: 8
INFO 04-01 18:22:36 [tpu_model_runner.py:874]   -- num_tokens: 64, num_seqs: 16
INFO 04-01 18:22:37 [tpu_model_runner.py:874]   -- num_tokens: 64, num_seqs: 32
INFO 04-01 18:22:38 [tpu_model_runner.py:874]   -- num_tokens: 64, num_seqs: 64
INFO 04-01 18:22:40 [tpu_model_runner.py:874]   -- num_tokens: 64, num_seqs: 128
INFO 04-01 18:22:42 [tpu_model_runner.py:874]   -- num_tokens: 128, num_seqs: 8
INFO 04-01 18:22:42 [tpu_model_runner.py:874]   -- num_tokens: 128, num_seqs: 16
INFO 04-01 18:22:43 [tpu_model_runner.py:874]   -- num_tokens: 128, num_seqs: 32
INFO 04-01 18:22:44 [tpu_model_runner.py:874]   -- num_tokens: 128, num_seqs: 64
INFO 04-01 18:22:46 [tpu_model_runner.py:874]   -- num_tokens: 128, num_seqs: 128
INFO 04-01 18:22:47 [tpu_model_runner.py:874]   -- num_tokens: 256, num_seqs: 8
INFO 04-01 18:22:48 [tpu_model_runner.py:874]   -- num_tokens: 256, num_seqs: 16
INFO 04-01 18:22:49 [tpu_model_runner.py:874]   -- num_tokens: 256, num_seqs: 32
INFO 04-01 18:22:50 [tpu_model_runner.py:874]   -- num_tokens: 256, num_seqs: 64
INFO 04-01 18:22:52 [tpu_model_runner.py:874]   -- num_tokens: 256, num_seqs: 128
INFO 04-01 18:22:53 [tpu_model_runner.py:874]   -- num_tokens: 512, num_seqs: 8
INFO 04-01 18:22:54 [tpu_model_runner.py:874]   -- num_tokens: 512, num_seqs: 16
INFO 04-01 18:22:55 [tpu_model_runner.py:874]   -- num_tokens: 512, num_seqs: 32
INFO 04-01 18:22:56 [tpu_model_runner.py:874]   -- num_tokens: 512, num_seqs: 64
INFO 04-01 18:22:57 [tpu_model_runner.py:874]   -- num_tokens: 512, num_seqs: 128
INFO 04-01 18:22:59 [tpu_model_runner.py:887] Compilation finished in in 34.58 [secs].
INFO 04-01 18:22:59 [core.py:167] init engine (profile, create kv cache, warmup model) took 195.44 seconds
WARNING 04-01 18:22:59 [config.py:1065] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 04-01 18:22:59 [serving_chat.py:114] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 04-01 18:23:00 [serving_completion.py:61] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 04-01 18:23:00 [api_server.py:1078] Starting vLLM API server on http://0.0.0.0:8000
INFO 04-01 18:23:00 [launcher.py:26] Available routes are:
INFO 04-01 18:23:00 [launcher.py:34] Route: /openapi.json, Methods: GET, HEAD
INFO 04-01 18:23:00 [launcher.py:34] Route: /docs, Methods: GET, HEAD
INFO 04-01 18:23:00 [launcher.py:34] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 04-01 18:23:00 [launcher.py:34] Route: /redoc, Methods: GET, HEAD
INFO 04-01 18:23:00 [launcher.py:34] Route: /health, Methods: GET
INFO 04-01 18:23:00 [launcher.py:34] Route: /load, Methods: GET
INFO 04-01 18:23:00 [launcher.py:34] Route: /ping, Methods: GET, POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /tokenize, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /detokenize, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /v1/models, Methods: GET
INFO 04-01 18:23:00 [launcher.py:34] Route: /version, Methods: GET
INFO 04-01 18:23:00 [launcher.py:34] Route: /v1/chat/completions, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /v1/completions, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /v1/embeddings, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /pooling, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /score, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /v1/score, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /v1/audio/transcriptions, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /rerank, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /v1/rerank, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /v2/rerank, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /invocations, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /start_profile, Methods: POST
INFO 04-01 18:23:00 [launcher.py:34] Route: /stop_profile, Methods: POST
INFO:     Started server process [298450]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO 04-01 18:23:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:23:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:23:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:23:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:23:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:24:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:24:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:24:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:24:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:24:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:24:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:25:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:25:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:25:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:25:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:25:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:25:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:26:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:26:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:26:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:26:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:26:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:26:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:27:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:27:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:27:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:27:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:27:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:27:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:28:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:28:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:28:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:28:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:28:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:28:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:29:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:29:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:29:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:29:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:29:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:29:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:30:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:30:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:30:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:30:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:30:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:30:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:31:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:31:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:31:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:31:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:31:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:31:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:32:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:32:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:32:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:32:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:32:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:32:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:33:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:33:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:33:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:33:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:33:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:33:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:34:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:34:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:59470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 04-01 18:34:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.5 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:45540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 04-01 18:34:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.5 tokens/s, Avg generation throughput: 0.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 04-01 18:34:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:49926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 04-01 18:34:50 [loggers.py:81] Engine 000: Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 1.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.2%, Prefix cache hit rate: 0.0%
INFO 04-01 18:35:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.2%, Prefix cache hit rate: 0.0%
INFO 04-01 18:35:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.2%, Prefix cache hit rate: 0.0%
INFO 04-01 18:35:11 [api_server.py:761] Starting profiler...
INFO 04-01 18:35:11 [api_server.py:763] Profiler started.
INFO:     127.0.0.1:42052 - "POST /start_profile HTTP/1.1" 200 OK
INFO:     127.0.0.1:42056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42198 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42340 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42366 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42422 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42442 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42462 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42488 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42500 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42514 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42522 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42526 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42546 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42562 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42578 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42606 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42658 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42668 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42686 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42692 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42694 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42718 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42736 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42780 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42796 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42836 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42914 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42934 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42982 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43012 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44898 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44912 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45138 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45198 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45206 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45268 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45360 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45374 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45384 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45522 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45574 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45590 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45612 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45638 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45664 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45684 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45694 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45734 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45774 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45780 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45804 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45814 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45838 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45864 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45870 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45882 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46024 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46384 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46442 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46444 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46456 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46468 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46488 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46506 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46514 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46616 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46658 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43198 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43276 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43340 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43366 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43406 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43420 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43464 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43488 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43522 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43532 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43544 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43570 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43582 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43606 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43622 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43636 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43698 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43700 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43714 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43732 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43736 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43738 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43794 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43800 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43812 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43822 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43838 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43862 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43898 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43920 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43962 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44016 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44082 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44138 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44360 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44376 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44408 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44442 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44462 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44588 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44590 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44646 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44700 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44712 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44722 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44734 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44788 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44800 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44806 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44862 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44870 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 04-01 18:35:20 [loggers.py:81] Engine 000: Avg prompt throughput: 1421.4 tokens/s, Avg generation throughput: 68.2 tokens/s, Running: 45 reqs, Waiting: 454 reqs, GPU KV cache usage: 8.1%, Prefix cache hit rate: 2.2%
INFO 04-01 18:35:30 [loggers.py:81] Engine 000: Avg prompt throughput: 1512.1 tokens/s, Avg generation throughput: 234.4 tokens/s, Running: 93 reqs, Waiting: 406 reqs, GPU KV cache usage: 17.0%, Prefix cache hit rate: 1.1%
INFO 04-01 18:35:40 [loggers.py:81] Engine 000: Avg prompt throughput: 1233.6 tokens/s, Avg generation throughput: 370.0 tokens/s, Running: 128 reqs, Waiting: 368 reqs, GPU KV cache usage: 24.9%, Prefix cache hit rate: 0.8%
INFO 04-01 18:35:50 [loggers.py:81] Engine 000: Avg prompt throughput: 1103.9 tokens/s, Avg generation throughput: 405.1 tokens/s, Running: 117 reqs, Waiting: 332 reqs, GPU KV cache usage: 23.1%, Prefix cache hit rate: 0.6%
INFO 04-01 18:36:00 [loggers.py:81] Engine 000: Avg prompt throughput: 1294.5 tokens/s, Avg generation throughput: 365.1 tokens/s, Running: 111 reqs, Waiting: 291 reqs, GPU KV cache usage: 21.5%, Prefix cache hit rate: 0.5%
INFO 04-01 18:36:10 [loggers.py:81] Engine 000: Avg prompt throughput: 1326.4 tokens/s, Avg generation throughput: 369.6 tokens/s, Running: 115 reqs, Waiting: 249 reqs, GPU KV cache usage: 22.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:36:20 [loggers.py:81] Engine 000: Avg prompt throughput: 1261.9 tokens/s, Avg generation throughput: 389.7 tokens/s, Running: 123 reqs, Waiting: 209 reqs, GPU KV cache usage: 23.8%, Prefix cache hit rate: 0.4%
INFO 04-01 18:36:30 [loggers.py:81] Engine 000: Avg prompt throughput: 1275.2 tokens/s, Avg generation throughput: 403.2 tokens/s, Running: 121 reqs, Waiting: 168 reqs, GPU KV cache usage: 23.3%, Prefix cache hit rate: 0.3%
INFO 04-01 18:36:40 [loggers.py:81] Engine 000: Avg prompt throughput: 1259.8 tokens/s, Avg generation throughput: 388.9 tokens/s, Running: 120 reqs, Waiting: 128 reqs, GPU KV cache usage: 23.1%, Prefix cache hit rate: 0.3%
INFO 04-01 18:36:50 [loggers.py:81] Engine 000: Avg prompt throughput: 1294.7 tokens/s, Avg generation throughput: 388.9 tokens/s, Running: 116 reqs, Waiting: 87 reqs, GPU KV cache usage: 22.3%, Prefix cache hit rate: 0.3%
INFO 04-01 18:37:00 [loggers.py:81] Engine 000: Avg prompt throughput: 1321.3 tokens/s, Avg generation throughput: 373.1 tokens/s, Running: 116 reqs, Waiting: 45 reqs, GPU KV cache usage: 22.5%, Prefix cache hit rate: 0.5%
INFO 04-01 18:37:10 [loggers.py:81] Engine 000: Avg prompt throughput: 1289.2 tokens/s, Avg generation throughput: 378.3 tokens/s, Running: 115 reqs, Waiting: 4 reqs, GPU KV cache usage: 22.1%, Prefix cache hit rate: 0.4%
INFO 04-01 18:37:20 [loggers.py:81] Engine 000: Avg prompt throughput: 159.2 tokens/s, Avg generation throughput: 351.3 tokens/s, Running: 81 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.1%, Prefix cache hit rate: 0.4%
INFO 04-01 18:37:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 220.2 tokens/s, Running: 39 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.5%, Prefix cache hit rate: 0.4%
INFO 04-01 18:37:37 [api_server.py:768] Stopping profiler...
INFO 04-01 18:37:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 61.3 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:37:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:38:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:38:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:38:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:38:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:38:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:38:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:38:50 [api_server.py:770] Profiler stopped.
INFO:     127.0.0.1:37198 - "POST /stop_profile HTTP/1.1" 200 OK
INFO 04-01 18:39:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:39:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:39:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:39:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:39:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:39:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:40:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:40:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:40:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:40:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:40:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:40:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:41:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:41:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:41:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:41:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:41:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:41:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:42:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:42:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:42:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:42:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:42:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:42:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:43:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:43:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:43:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:43:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:43:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:43:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:44:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:44:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:44:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:44:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:44:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:44:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:45:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:45:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:45:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:45:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:45:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:45:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:46:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:46:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:46:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:46:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:46:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:46:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:47:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:47:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:47:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:47:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:47:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:47:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:48:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:48:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:48:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:48:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:48:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:48:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:49:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:49:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:49:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:49:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:49:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:49:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:50:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:50:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:50:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:50:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:50:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:50:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:51:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:51:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:51:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:51:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:51:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:51:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:52:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:52:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:52:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:52:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:52:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:52:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:53:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:53:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:53:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:53:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:53:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:53:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:54:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:54:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:54:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:54:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:54:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:54:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:55:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:55:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:55:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:55:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:55:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:55:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:56:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:56:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:56:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:56:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:56:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:56:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:57:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:57:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:57:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:57:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:57:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:57:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:58:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:58:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:58:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:58:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:58:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:58:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:59:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:59:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:59:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:59:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:59:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 18:59:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:00:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:00:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:00:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:00:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:00:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:00:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:01:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:01:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:01:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:01:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:01:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:01:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:02:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:02:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:02:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:02:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:02:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:02:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:03:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:03:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:03:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:03:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:03:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:03:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:04:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:04:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:04:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:04:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:04:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:04:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:05:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:05:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:05:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:05:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:05:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:05:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:06:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:06:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:06:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:06:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:06:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:06:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:07:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:07:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:07:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:07:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:07:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:07:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:08:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:08:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:08:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:08:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:08:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:08:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:09:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:09:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:09:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:09:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:09:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:09:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:10:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:10:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:10:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:10:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:10:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:10:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:11:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:11:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:11:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:11:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:11:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:11:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:12:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:12:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:12:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:12:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:12:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:12:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:13:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:13:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:13:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:13:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:13:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:13:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:14:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:14:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:14:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:14:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:14:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:14:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:15:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:15:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:15:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:15:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:15:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:15:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:16:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:16:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:16:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:16:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:16:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:16:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:17:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:17:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:17:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:17:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:17:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:17:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:18:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:18:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:18:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:18:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:18:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:18:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:19:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:19:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:19:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:19:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:19:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:19:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:20:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:20:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:20:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:20:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:20:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:20:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:21:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:21:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:21:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:21:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:21:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:21:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:22:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:22:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:22:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:22:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:22:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:22:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:23:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:23:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:23:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:23:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:23:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:23:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:24:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:24:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:24:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:24:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:24:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:24:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:25:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:25:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:25:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:25:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:25:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:25:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:26:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:26:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:26:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:26:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:26:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:26:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:27:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:27:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:27:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:27:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:27:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:27:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:28:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:28:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:28:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:28:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:28:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:28:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:29:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:29:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:29:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:29:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:29:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:29:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:30:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:30:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:30:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:30:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:30:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:30:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:31:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:31:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:31:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:31:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:31:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:31:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:32:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:32:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:32:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:32:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:32:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:32:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:33:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:33:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:33:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:33:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:33:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:33:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:34:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:34:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:34:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:34:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:34:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:34:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:35:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:35:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:35:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:35:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:35:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:35:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:36:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:36:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:36:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:36:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:36:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:36:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:37:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:37:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:37:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:37:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:37:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:37:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:38:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:38:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:38:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:38:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:38:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:38:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:39:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:39:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:39:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:39:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:39:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:39:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:40:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:40:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:40:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:40:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:40:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:40:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:41:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:41:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:41:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:41:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:41:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:41:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:42:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:42:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:42:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:42:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:42:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:42:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:43:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:43:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:43:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:43:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:43:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:43:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:44:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:44:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:44:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:44:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:44:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:44:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:45:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:45:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:45:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:45:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:45:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:45:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:46:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:46:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:46:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:46:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:46:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:46:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:47:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:47:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:47:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:47:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:47:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:47:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:48:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:48:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:48:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:48:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:48:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:48:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:49:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:49:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:49:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:49:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:49:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:49:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:50:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:50:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:50:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:50:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:50:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:50:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:51:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:51:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:51:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:51:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:51:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:51:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:52:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:52:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:52:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:52:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:52:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:52:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:53:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:53:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:53:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:53:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:53:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:53:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:54:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:54:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:54:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:54:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:54:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:54:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:55:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:55:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:55:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:55:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:55:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:55:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:56:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:56:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:56:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:56:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:56:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:56:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:57:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:57:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:57:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:57:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:57:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:57:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:58:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:58:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:58:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:58:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:58:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:58:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:59:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:59:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:59:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:59:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:59:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 19:59:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:00:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:00:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:00:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:00:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:00:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:00:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:01:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:01:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:01:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:01:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:01:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:01:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:02:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:02:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:02:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:02:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:02:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:02:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:03:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:03:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:03:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:03:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:03:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:03:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:04:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:04:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:04:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:04:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:04:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:04:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:05:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:05:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:05:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:05:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:05:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:05:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:06:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:06:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:06:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:06:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:06:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:06:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:07:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:07:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:07:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:07:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:07:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:07:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:08:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:08:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:08:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:08:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:08:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:08:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:09:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:09:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:09:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:09:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:09:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:09:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:10:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:10:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:10:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:10:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:10:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:10:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:11:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:11:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:11:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:11:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:11:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:11:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:12:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:12:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:12:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:12:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:12:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:12:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:13:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:13:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:13:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:13:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:13:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:13:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:14:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:14:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:14:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:14:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:14:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:14:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:15:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:15:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:15:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:15:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:15:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:15:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:16:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:16:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:16:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:16:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:16:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:16:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:17:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:17:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:17:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:17:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:17:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:17:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:18:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:18:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:18:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:18:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:18:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:18:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:19:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:19:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:19:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:19:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:19:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:19:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:20:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:20:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:20:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:20:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:20:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:20:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:21:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:21:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:21:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:21:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:21:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:21:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:22:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:22:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:22:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:22:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:22:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:22:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:23:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:23:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:23:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:23:30 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:23:40 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:23:50 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:24:00 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:24:10 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 04-01 20:24:20 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
