nohup: ignoring input
INFO 03-31 15:21:26 [__init__.py:239] Automatically detected platform tpu.
WARNING 03-31 15:21:28 [api_server.py:755] Torch Profiler is enabled in the API server. This should ONLY be used for local development!
INFO 03-31 15:21:28 [api_server.py:1031] vLLM API server version 0.7.4.dev811+gc1d633ce7
INFO 03-31 15:21:28 [api_server.py:1032] args: Namespace(subparser='serve', model_tag='meta-llama/Meta-Llama-3.1-8B', config='', host=None, port=8000, uvicorn_log_level='info', disable_uvicorn_access_log=False, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Meta-Llama-3.1-8B', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir='/dev/shm', load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=512, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=4, data_parallel_size=1, enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, prefix_caching_hash_algo='builtin', disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=None, swap_space=16.0, cpu_offload_gb=0, gpu_memory_utilization=0.95, num_gpu_blocks_override=None, max_num_batched_tokens=512, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=128, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, use_tqdm_on_load=True, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_config=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', worker_extension_cls='', generation_config='auto', override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, enable_reasoning=False, reasoning_parser=None, disable_cascade_attn=False, disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, enable_server_load_tracking=False, dispatch_function=<function ServeSubcommand.cmd at 0x742b82168af0>)
INFO 03-31 15:21:37 [config.py:593] This model supports multiple tasks: {'score', 'classify', 'reward', 'generate', 'embed'}. Defaulting to 'generate'.
WARNING 03-31 15:21:37 [arg_utils.py:1880] Detected VLLM_USE_V1=1 with tpu. Usage should be considered experimental. Please report any issues on Github.
INFO 03-31 15:21:37 [config.py:1559] Defaulting to use mp for distributed inference
INFO 03-31 15:21:37 [config.py:1738] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 03-31 15:21:37 [tpu.py:81] [TPU] Forcing DYNAMO_ONCE compilation level
INFO 03-31 15:21:41 [__init__.py:239] Automatically detected platform tpu.
INFO 03-31 15:21:43 [core.py:60] Initializing a V1 LLM engine (v0.7.4.dev811+gc1d633ce7) with config: model='meta-llama/Meta-Llama-3.1-8B', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir='/dev/shm', load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=None, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Meta-Llama-3.1-8B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":2,"backend":"openxla","custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 03-31 15:21:43 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 90 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-31 15:21:43 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_6143635a'), local_subscribe_addr='ipc:///tmp/eae23b51-a2af-4c1f-bb3f-f6eedc5f27bc', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-31 15:21:46 [__init__.py:239] Automatically detected platform tpu.
WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.
INFO 03-31 15:21:49 [tpu_worker.py:79] Profiling enabled. Traces will be saved to: gs://hosseins-asia-northeast1-bucket/vllm/profile-main
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:21:49 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_812c981a'), local_subscribe_addr='ipc:///tmp/39cd72b0-0bf0-49d7-8821-faa6e611c483', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-31 15:21:52 [__init__.py:239] Automatically detected platform tpu.
WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:21:54 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d66a55c0'), local_subscribe_addr='ipc:///tmp/e4e99a2f-be70-49ed-8b9b-294a1f8578f5', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-31 15:21:57 [__init__.py:239] Automatically detected platform tpu.
WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:00 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_07fd123c'), local_subscribe_addr='ipc:///tmp/cf67907b-8e48-4610-875e-80ac0723334e', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-31 15:22:03 [__init__.py:239] Automatically detected platform tpu.
WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:05 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6b462802'), local_subscribe_addr='ipc:///tmp/5a4089b7-20cb-46bc-b463-c2659bf7e71b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:05 [tpu_communicator.py:61] TpuCommunicator initialized with MP
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:05 [tpu_communicator.py:61] TpuCommunicator initialized with MP
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:05 [tpu_communicator.py:61] TpuCommunicator initialized with MP
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:05 [tpu_communicator.py:61] TpuCommunicator initialized with MP
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_3a0166f8'), local_subscribe_addr='ipc:///tmp/7b4e0773-355f-48f5-a868-caea9729e1bd', remote_subscribe_addr=None, remote_addr_ipv6=False)
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:13 [parallel_state.py:954] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [parallel_state.py:954] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:13 [parallel_state.py:954] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:13 [parallel_state.py:954] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=67315)[0;0m WARNING 03-31 15:22:13 [tpu.py:121] Pin memory is not supported on TPU.
[1;36m(VllmWorker rank=0 pid=67221)[0;0m WARNING 03-31 15:22:13 [tpu.py:121] Pin memory is not supported on TPU.
[1;36m(VllmWorker rank=2 pid=67291)[0;0m WARNING 03-31 15:22:13 [tpu.py:121] Pin memory is not supported on TPU.
[1;36m(VllmWorker rank=1 pid=67265)[0;0m WARNING 03-31 15:22:13 [tpu.py:121] Pin memory is not supported on TPU.
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:976] Using exponential paddings:
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:976] Using exponential paddings:
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     16
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     64
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     256
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     512
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     32
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     128
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     256
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     512
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:976] Using exponential paddings:
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:976] Using exponential paddings:
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     32
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     64
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     128
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     256
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     512
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     32
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     128
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     256
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:13 [tpu_model_runner.py:978]     512
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:14 [tpu.py:44] Cannot use None backend on TPU.
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:14 [tpu.py:44] Cannot use None backend on TPU.
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:14 [tpu.py:47] Using Pallas V1 backend.
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:14 [tpu.py:47] Using Pallas V1 backend.
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:14 [tpu.py:44] Cannot use None backend on TPU.
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:14 [tpu.py:47] Using Pallas V1 backend.
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:14 [tpu.py:44] Cannot use None backend on TPU.
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:14 [tpu.py:47] Using Pallas V1 backend.
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:14 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:14 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:14 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:15 [weight_utils.py:265] Using model weights format ['*.safetensors']
2025-03-31 15:22:15.614191: W torch_xla/csrc/xla_graph_executor.cpp:105] Using persistent compilation cache with XLA_HLO_DEBUG=1 or XLA_IR_DEBUG=1 is not recommended. Changes to the HLO metadata will not be reflected in loaded executables.
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: ============================= Layers Loaded =============================
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [embed_tokens.weight] - [torch.Size([32064, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [norm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: ============================= Layers Loaded =============================
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [embed_tokens.weight] - [torch.Size([32064, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [norm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:16 [loader.py:447] Loading weights took 0.70 seconds
2025-03-31 15:22:16.685381: W torch_xla/csrc/xla_graph_executor.cpp:105] Using persistent compilation cache with XLA_HLO_DEBUG=1 or XLA_IR_DEBUG=1 is not recommended. Changes to the HLO metadata will not be reflected in loaded executables.
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: ============================= Layers Loaded =============================
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [embed_tokens.weight] - [torch.Size([32064, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [norm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: ============================= Layers Loaded =============================
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [embed_tokens.weight] - [torch.Size([32064, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [norm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:17 [loader.py:447] Loading weights took 0.70 seconds
2025-03-31 15:22:17.415617: W torch_xla/csrc/xla_graph_executor.cpp:105] Using persistent compilation cache with XLA_HLO_DEBUG=1 or XLA_IR_DEBUG=1 is not recommended. Changes to the HLO metadata will not be reflected in loaded executables.
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: ============================= Layers Loaded =============================
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [embed_tokens.weight] - [torch.Size([32064, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [norm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: ============================= Layers Loaded =============================
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [embed_tokens.weight] - [torch.Size([32064, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [norm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:18 [loader.py:447] Loading weights took 0.72 seconds
[1;36m(VllmWorker rank=0 pid=67221)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
2025-03-31 15:22:18.150116: W torch_xla/csrc/xla_graph_executor.cpp:105] Using persistent compilation cache with XLA_HLO_DEBUG=1 or XLA_IR_DEBUG=1 is not recommended. Changes to the HLO metadata will not be reflected in loaded executables.
[1;36m(VllmWorker rank=0 pid=67221)[0;0m Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:00,  5.93it/s]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: ============================= Layers Loaded =============================
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [embed_tokens.weight] - [torch.Size([32064, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m [1;36m(VllmWorker rank=0 pid=67221)[0;0m Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  6.65it/s]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:00<00:00,  6.52it/s]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:00<00:00,  5.19it/s]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:00<00:00,  5.59it/s]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m 
hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [norm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: ============================= Layers Loaded =============================
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [embed_tokens.weight] - [torch.Size([32064, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.0.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.1.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.2.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.3.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.4.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.5.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.6.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.7.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.8.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.9.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.10.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.11.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.12.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.13.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.14.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.15.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.16.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.17.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.18.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.19.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.20.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.21.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.22.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.23.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.24.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.25.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.26.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.27.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.28.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.29.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.30.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.self_attn.qkv_proj.weight] - [torch.Size([1536, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.self_attn.o_proj.weight] - [torch.Size([4096, 1024])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.mlp.gate_up_proj.weight] - [torch.Size([7168, 4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.mlp.down_proj.weight] - [torch.Size([4096, 3584])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.input_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [layers.31.post_attention_layernorm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [norm.weight] - [torch.Size([4096])]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:18 [loader.py:447] Loading weights took 0.80 seconds
INFO 03-31 15:22:39 [kv_cache_utils.py:577] GPU KV cache size: 844,816 tokens
INFO 03-31 15:22:39 [kv_cache_utils.py:580] Maximum concurrency for 512 tokens per request: 1650.03x
INFO 03-31 15:22:39 [kv_cache_utils.py:577] GPU KV cache size: 844,816 tokens
INFO 03-31 15:22:39 [kv_cache_utils.py:580] Maximum concurrency for 512 tokens per request: 1650.03x
INFO 03-31 15:22:39 [kv_cache_utils.py:577] GPU KV cache size: 844,816 tokens
INFO 03-31 15:22:39 [kv_cache_utils.py:580] Maximum concurrency for 512 tokens per request: 1650.03x
INFO 03-31 15:22:39 [kv_cache_utils.py:577] GPU KV cache size: 844,816 tokens
INFO 03-31 15:22:39 [kv_cache_utils.py:580] Maximum concurrency for 512 tokens per request: 1650.03x
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_spec={'model.layers.0.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.1.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.2.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.3.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.4.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.5.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.6.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.7.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.8.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.9.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.10.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.11.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.12.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.13.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.14.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.15.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.16.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.17.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.18.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.19.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.20.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.21.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.22.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.23.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.24.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.25.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.26.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.27.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.28.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.29.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.30.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.31.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False)}]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:39 [tpu_model_runner.py:784] Compiling the model with different input shapes.
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_spec={'model.layers.0.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.1.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.2.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.3.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.4.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.5.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.6.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.7.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.8.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.9.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.10.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.11.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.12.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.13.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.14.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.15.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.16.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.17.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.18.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.19.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.20.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.21.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.22.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.23.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.24.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.25.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.26.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.27.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.28.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.29.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.30.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.31.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False)}]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:39 [tpu_model_runner.py:784] Compiling the model with different input shapes.
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_spec={'model.layers.0.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.1.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.2.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.3.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.4.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.5.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.6.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.7.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.8.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.9.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.10.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.11.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.12.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.13.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.14.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.15.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.16.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.17.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.18.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.19.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.20.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.21.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.22.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.23.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.24.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.25.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.26.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.27.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.28.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.29.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.30.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.31.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False)}]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:39 [tpu_model_runner.py:784] Compiling the model with different input shapes.
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_spec={'model.layers.0.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.1.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.2.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.3.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.4.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.5.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.6.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.7.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.8.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.9.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.10.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.11.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.12.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.13.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.14.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.15.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.16.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.17.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.18.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.19.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.20.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.21.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.22.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.23.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.24.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.25.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.26.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.27.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.28.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.29.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.30.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False), 'model.layers.31.self_attn.attn': FullAttentionSpec(block_size=16, num_kv_heads=2, head_size=128, dtype=torch.bfloat16, use_mla=False)}]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m hosseins: [kv_cache_shape=(52801, 16, 4, 128)]
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:39 [tpu_model_runner.py:784] Compiling the model with different input shapes.
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:22:39 [tpu_model_runner.py:788]   -- num_tokens: 16
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:22:39 [tpu_model_runner.py:788]   -- num_tokens: 16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:22:39 [tpu_model_runner.py:788]   -- num_tokens: 16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:22:39 [tpu_model_runner.py:788]   -- num_tokens: 16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m /home/hosseins/miniconda3/envs/vllm-march/lib/python3.10/site-packages/jax/_src/cloud_tpu_init.py:82: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c "echo always > /sys/kernel/mm/transparent_hugepage/enabled")
[1;36m(VllmWorker rank=2 pid=67291)[0;0m   warnings.warn(
[1;36m(VllmWorker rank=1 pid=67265)[0;0m /home/hosseins/miniconda3/envs/vllm-march/lib/python3.10/site-packages/jax/_src/cloud_tpu_init.py:82: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c "echo always > /sys/kernel/mm/transparent_hugepage/enabled")
[1;36m(VllmWorker rank=1 pid=67265)[0;0m   warnings.warn(
[1;36m(VllmWorker rank=0 pid=67221)[0;0m /home/hosseins/miniconda3/envs/vllm-march/lib/python3.10/site-packages/jax/_src/cloud_tpu_init.py:82: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c "echo always > /sys/kernel/mm/transparent_hugepage/enabled")
[1;36m(VllmWorker rank=0 pid=67221)[0;0m   warnings.warn(
[1;36m(VllmWorker rank=3 pid=67315)[0;0m /home/hosseins/miniconda3/envs/vllm-march/lib/python3.10/site-packages/jax/_src/cloud_tpu_init.py:82: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c "echo always > /sys/kernel/mm/transparent_hugepage/enabled")
[1;36m(VllmWorker rank=3 pid=67315)[0;0m   warnings.warn(
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:12 [tpu_model_runner.py:788]   -- num_tokens: 32
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:12 [tpu_model_runner.py:788]   -- num_tokens: 32
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:12 [tpu_model_runner.py:788]   -- num_tokens: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:12 [tpu_model_runner.py:788]   -- num_tokens: 32
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:18 [tpu_model_runner.py:788]   -- num_tokens: 64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:18 [tpu_model_runner.py:788]   -- num_tokens: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:18 [tpu_model_runner.py:788]   -- num_tokens: 64
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:18 [tpu_model_runner.py:788]   -- num_tokens: 64
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:24 [tpu_model_runner.py:788]   -- num_tokens: 128
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:25 [tpu_model_runner.py:788]   -- num_tokens: 128
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:25 [tpu_model_runner.py:788]   -- num_tokens: 128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:25 [tpu_model_runner.py:788]   -- num_tokens: 128
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:31 [tpu_model_runner.py:788]   -- num_tokens: 256
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:32 [tpu_model_runner.py:788]   -- num_tokens: 256
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:32 [tpu_model_runner.py:788]   -- num_tokens: 256
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:32 [tpu_model_runner.py:788]   -- num_tokens: 256
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:40 [tpu_model_runner.py:788]   -- num_tokens: 512
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:40 [tpu_model_runner.py:788]   -- num_tokens: 512
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:40 [tpu_model_runner.py:788]   -- num_tokens: 512
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:40 [tpu_model_runner.py:788]   -- num_tokens: 512
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:793] Compilation finished in in 69.87 [secs].
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:793] Compilation finished in in 69.87 [secs].
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:793] Compilation finished in in 69.87 [secs].
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:793] Compilation finished in in 69.87 [secs].
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:795] Compiling sampling with different input shapes.
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:795] Compiling sampling with different input shapes.
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:795] Compiling sampling with different input shapes.
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:795] Compiling sampling with different input shapes.
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 8
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 8
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 8
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 8
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 16
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 32
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 32
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 64
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 128
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 128
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 16, num_seqs: 128
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 8
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 8
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 8
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 8
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 16
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 16
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 32
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 32
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:49 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 64
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 128
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 128
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 32, num_seqs: 128
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 8
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 8
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 8
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 8
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 16
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 16
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 16
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 32
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 32
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 32
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 32
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 64
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 64
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 128
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 128
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 64, num_seqs: 128
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 8
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 8
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 8
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 8
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 16
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 32
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 32
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 32
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 64
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 128
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 128
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 128, num_seqs: 128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 8
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 8
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 8
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 8
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 16
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 16
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 16
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 32
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 32
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 32
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 64
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 64
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 64
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 128
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 128
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 128
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 256, num_seqs: 128
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 8
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 8
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 8
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 8
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 16
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 16
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 16
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 32
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 32
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:50 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 32
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 64
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 64
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 64
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 128
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 128
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:816]   -- num_tokens: 512, num_seqs: 128
[1;36m(VllmWorker rank=3 pid=67315)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:828] Compilation finished in 1.47 [secs].
[1;36m(VllmWorker rank=0 pid=67221)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:828] Compilation finished in 1.47 [secs].
[1;36m(VllmWorker rank=1 pid=67265)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:828] Compilation finished in 1.47 [secs].
[1;36m(VllmWorker rank=2 pid=67291)[0;0m INFO 03-31 15:23:51 [tpu_model_runner.py:828] Compilation finished in 1.47 [secs].
INFO 03-31 15:23:51 [core.py:159] init engine (profile, create kv cache, warmup model) took 92.15 seconds
WARNING 03-31 15:23:51 [config.py:1046] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 03-31 15:23:51 [serving_chat.py:114] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 03-31 15:23:51 [serving_completion.py:61] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 03-31 15:23:51 [api_server.py:1078] Starting vLLM API server on http://0.0.0.0:8000
INFO 03-31 15:23:51 [launcher.py:26] Available routes are:
INFO 03-31 15:23:51 [launcher.py:34] Route: /openapi.json, Methods: GET, HEAD
INFO 03-31 15:23:51 [launcher.py:34] Route: /docs, Methods: GET, HEAD
INFO 03-31 15:23:51 [launcher.py:34] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 03-31 15:23:51 [launcher.py:34] Route: /redoc, Methods: GET, HEAD
INFO 03-31 15:23:51 [launcher.py:34] Route: /health, Methods: GET
INFO 03-31 15:23:51 [launcher.py:34] Route: /load, Methods: GET
INFO 03-31 15:23:51 [launcher.py:34] Route: /ping, Methods: POST, GET
INFO 03-31 15:23:51 [launcher.py:34] Route: /tokenize, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /detokenize, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /v1/models, Methods: GET
INFO 03-31 15:23:51 [launcher.py:34] Route: /version, Methods: GET
INFO 03-31 15:23:51 [launcher.py:34] Route: /v1/chat/completions, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /v1/completions, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /v1/embeddings, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /pooling, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /score, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /v1/score, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /v1/audio/transcriptions, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /rerank, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /v1/rerank, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /v2/rerank, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /invocations, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /start_profile, Methods: POST
INFO 03-31 15:23:51 [launcher.py:34] Route: /stop_profile, Methods: POST
INFO:     Started server process [66949]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO 03-31 15:24:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:24:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:24:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:24:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:24:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:24:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:25:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:25:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:25:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:25:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:25:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:25:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-31 15:26:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:42312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 03-31 15:26:05 [api_server.py:761] Starting profiler...
INFO 03-31 15:26:05 [api_server.py:763] Profiler started.
INFO:     127.0.0.1:42322 - "POST /start_profile HTTP/1.1" 200 OK
INFO:     127.0.0.1:44324 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44338 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44354 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44360 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44416 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44452 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44508 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44526 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44574 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44588 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44606 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44630 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44684 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42354 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42370 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42406 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42436 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42522 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42526 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42556 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42574 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42582 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42630 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42664 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42700 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42792 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42814 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42830 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42870 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42912 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42914 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42924 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42940 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43108 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43112 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43190 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43228 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43338 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43370 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43392 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43430 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43450 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43488 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43514 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43546 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43574 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43580 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43598 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43640 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43736 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43774 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43776 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43792 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43804 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43854 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43864 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43894 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43898 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44138 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44692 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44698 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44702 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44714 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45668 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45692 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45696 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45738 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45792 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45800 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45804 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45816 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45890 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45892 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45900 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45918 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45940 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45962 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46206 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46370 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46384 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46408 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46464 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46484 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46500 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46528 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46564 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46578 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46616 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46626 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46636 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46650 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46684 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46698 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46704 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46732 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46766 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:46770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44720 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44730 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44750 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44800 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44810 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44852 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44946 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45024 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45190 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45338 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45378 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45384 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45410 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45422 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45480 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45528 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45598 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45630 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45654 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 03-31 15:26:12 [loggers.py:81] Engine 000: Avg prompt throughput: 5815.9 tokens/s, Avg generation throughput: 1234.0 tokens/s, Running: 116 reqs, Waiting: 315 reqs, GPU KV cache usage: 5.6%, Prefix cache hit rate: 0.6%
INFO 03-31 15:26:22 [loggers.py:81] Engine 000: Avg prompt throughput: 7758.2 tokens/s, Avg generation throughput: 2288.5 tokens/s, Running: 121 reqs, Waiting: 69 reqs, GPU KV cache usage: 5.8%, Prefix cache hit rate: 0.2%
INFO 03-31 15:26:27 [api_server.py:768] Stopping profiler...
INFO 03-31 15:26:32 [loggers.py:81] Engine 000: Avg prompt throughput: 2210.9 tokens/s, Avg generation throughput: 1244.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:26:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:26:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:26:52 [api_server.py:770] Profiler stopped.
INFO:     127.0.0.1:47394 - "POST /stop_profile HTTP/1.1" 200 OK
INFO 03-31 15:27:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:27:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:27:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:27:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:27:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:27:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:28:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:28:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:28:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:28:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:28:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:28:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:29:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:29:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:29:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:29:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:29:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:29:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:30:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:30:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:30:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:30:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:30:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:30:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:31:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:31:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:31:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:31:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:31:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:31:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:32:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:32:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:32:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:32:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:32:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:32:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:33:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:33:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:33:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:33:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:33:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:33:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:34:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:34:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:34:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:34:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:34:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:34:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:35:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:35:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:35:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:35:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:35:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:35:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:36:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:36:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:36:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:36:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:36:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:36:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:37:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:37:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:37:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:37:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:37:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:37:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:38:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:38:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:38:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:38:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:38:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:38:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:39:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:39:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:39:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:39:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:39:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:39:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:40:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:40:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:40:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:40:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:40:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:40:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:41:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:41:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:41:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:41:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:41:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:41:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:42:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:42:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:42:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:42:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:42:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:42:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:43:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:43:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:43:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:43:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:43:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:43:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:44:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:44:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:44:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:44:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:44:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:44:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:45:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:45:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:45:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:45:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:45:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:45:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:46:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:46:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:46:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:46:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:46:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:46:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:47:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:47:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:47:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:47:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:47:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:47:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:48:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:48:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:48:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:48:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:48:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:48:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:49:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:49:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:49:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:49:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:49:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:49:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:50:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:50:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:50:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:50:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:50:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:50:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:51:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:51:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:51:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:51:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:51:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:51:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:52:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:52:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:52:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:52:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:52:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:52:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:53:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:53:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:53:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:53:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:53:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:53:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:54:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:54:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:54:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:54:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:54:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:54:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:55:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:55:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:55:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:55:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:55:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:55:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:56:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:56:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:56:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:56:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:56:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:56:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:57:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:57:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:57:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:57:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:57:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:57:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:58:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:58:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:58:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:58:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:58:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:58:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:59:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:59:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:59:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:59:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:59:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 15:59:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:00:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:00:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:00:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:00:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:00:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:00:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:01:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:01:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:01:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:01:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:01:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:01:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:02:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:02:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:02:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:02:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:02:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:02:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:03:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:03:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:03:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:03:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:03:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:03:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:04:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:04:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:04:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:04:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:04:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:04:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:05:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:05:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:05:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:05:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:05:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:05:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:06:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:06:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:06:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:06:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:06:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:06:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:07:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:07:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:07:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:07:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:07:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:07:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:08:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:08:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:08:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:08:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:08:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:08:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:09:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:09:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:09:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:09:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:09:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:09:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:10:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:10:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:10:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:10:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:10:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:10:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:11:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:11:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:11:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:11:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:11:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:11:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:12:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:12:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:12:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:12:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:12:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:12:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:13:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:13:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:13:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:13:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:13:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:13:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:14:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:14:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:14:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:14:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:14:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:14:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:15:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:15:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:15:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:15:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:15:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:15:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:16:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:16:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:16:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:16:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:16:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:16:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:17:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:17:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:17:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:17:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:17:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:17:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:18:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:18:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:18:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:18:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:18:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:18:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:19:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:19:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:19:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:19:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:19:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:19:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:20:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:20:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:20:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:20:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:20:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:20:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:21:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:21:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:21:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:21:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:21:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:21:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:22:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:22:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:22:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:22:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:22:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:22:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:23:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:23:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:23:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:23:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:23:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:23:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:24:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:24:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:24:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:24:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:24:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:24:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:25:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:25:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:25:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:25:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:25:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:25:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:26:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:26:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:26:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:26:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:26:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:26:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:27:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:27:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:27:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:27:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:27:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:27:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:28:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:28:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:28:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:28:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:28:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:28:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:29:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:29:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:29:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:29:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:29:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:29:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:30:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:30:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:30:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:30:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:30:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:30:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:31:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:31:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:31:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:31:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:31:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:31:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:32:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:32:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:32:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:32:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:32:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:32:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:33:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:33:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:33:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:33:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:33:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:33:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:34:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:34:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:34:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:34:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:34:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:34:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:35:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:35:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:35:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:35:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:35:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:35:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:36:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:36:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:36:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:36:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:36:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:36:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:37:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:37:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:37:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:37:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:37:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:37:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:38:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:38:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:38:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:38:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:38:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:38:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:39:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:39:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:39:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:39:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:39:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:39:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:40:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:40:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:40:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:40:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:40:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:40:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:41:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:41:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:41:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:41:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:41:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:41:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:42:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:42:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:42:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:42:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:42:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:42:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:43:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:43:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:43:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:43:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:43:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:43:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:44:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:44:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:44:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:44:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:44:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:44:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:45:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:45:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:45:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:45:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:45:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:45:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:46:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:46:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:46:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:46:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:46:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:46:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:47:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:47:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:47:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:47:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:47:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:47:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:48:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:48:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:48:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:48:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:48:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:48:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:49:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:49:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:49:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:49:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:49:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:49:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:50:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:50:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:50:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:50:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:50:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:50:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:51:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:51:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:51:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:51:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:51:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:51:52 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:52:02 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:52:12 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:52:22 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:52:32 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
INFO 03-31 16:52:42 [loggers.py:81] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.4%
